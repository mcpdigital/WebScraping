{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EDA Web Scraper (Jupyter)</h1>\n",
    "<h2>Version Works fine, avoid modding</h2>\n",
    "<h3>1.0.0</h3>\n",
    "<p>Initial version</p>\n",
    "<p>Usage: 1-Search what you want, filter the tags and classes and press Save to save the results</p>\n",
    "<p>Usage: 2-Copy the search strings that returns the desired data in one of the five inputs bellow search and Press Scrape to join all RESULTS and save</p>\n",
    "<p>Usage: 3-Scrape more</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Web Scraper - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x1100\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://mercadolivre.com.br/\")\n",
    "        self.select_label = ttk.Label(master, text=\"Search html tags, css classes:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "        self.columns_label = ttk.Label(master, text=\"Columns Names:\\nLeave blank defaults to\\nsearch string\")\n",
    "\n",
    "        # Add 5 input fields for saving columns\n",
    "        self.save_entries = [ttk.Entry(master, width=80) for _ in range(5)]\n",
    "\n",
    "        # Add 5 input fields for custom column names\n",
    "        self.column_name_entries = [ttk.Entry(master, width=20) for _ in range(5)]\n",
    "\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.search_button = ttk.Button(master, text=\"Search\", command=self.search)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save)\n",
    "\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.columns_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.search_button.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.save_button.grid(row=2, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        # Place the save entries in the grid\n",
    "        for i, entry in enumerate(self.save_entries):\n",
    "            entry.grid(row=i + 3, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        # Place the column name entries in the grid\n",
    "        for i, entry in enumerate(self.column_name_entries):\n",
    "            entry.grid(row=i + 3, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "        \n",
    "        self.scrape_button.grid(row=9, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=10, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        \n",
    "\n",
    "        master.rowconfigure(10, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def search(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', 'Content-Type': 'text/html'}\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # if(select.rfind(\".\") == -1):\n",
    "        if (select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1):\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "        \n",
    "        \n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            \n",
    "            result_dict = {'Result Number': count, 'Result Text': str(result.text.strip())}\n",
    "            self.result_list.append(result_dict)  # add result to list\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result.text.strip()}\\n\\n\")\n",
    "            count += 1\n",
    "        \n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        # Combine the column names and values from the save_entries\n",
    "        columns = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "        if not columns:\n",
    "            messagebox.showerror(\"Error\", \"No columns to save.\")\n",
    "            return\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Perform searches for each of the columns\n",
    "        column_results = []\n",
    "        for column in columns:\n",
    "            if column.startswith(\".\") or column.rfind(\".\") != -1 or column.rfind(\" \") != -1:\n",
    "                results = soup.select(column)\n",
    "            else:\n",
    "                results = soup.find_all(column)\n",
    "\n",
    "            column_results.append([result.text.strip() for result in results])\n",
    "\n",
    "        # Create a pandas dataframe with the results\n",
    "        max_rows = max([len(column_data) for column_data in column_results])\n",
    "        data = []\n",
    "        for row_idx in range(max_rows):\n",
    "            row = [column_data[row_idx] if row_idx < len(column_data) else '' for column_data in column_results]\n",
    "            data.append(row)\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Replace default column names with custom names if provided\n",
    "        custom_columns = [entry.get() for entry in self.column_name_entries]\n",
    "        final_columns = {default: custom if custom else default for custom, default in zip(custom_columns, columns)}\n",
    "        df.rename(columns=final_columns, inplace=True)\n",
    "\n",
    "        # Save the results as a CSV file\n",
    "        filetypes = [('JSON files', '*.json'), ('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            if filename.endswith('.csv'):\n",
    "                df.to_csv(filename, index=False, encoding='utf-8')\n",
    "            elif filename.endswith('.json'):\n",
    "                df.to_json(filename, index=False, encoding='utf-8')\n",
    "\n",
    "            # Perform any desired operations on the dataframe\n",
    "            # Example: print the first 5 rows of the dataframe\n",
    "            print(df.head())\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        # use file dialog to get the filename and file type to save\n",
    "        filetypes = [('JSON files', '*.json'), ('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".json\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            selected_results = []  # list to save selected results\n",
    "\n",
    "            # create a Toplevel window to display checkboxes for each result\n",
    "            top = tk.Toplevel(self.master)\n",
    "            top.title(\"Select Results to Save\")\n",
    "            top.geometry(\"1280x720\")\n",
    "\n",
    "            # create a canvas to hold the checkboxes\n",
    "            canvas = tk.Canvas(top)\n",
    "            canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            # add a scrollbar to the canvas\n",
    "            yscrollbar = ttk.Scrollbar(top, orient=tk.VERTICAL, command=canvas.yview)\n",
    "            yscrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "            canvas.configure(yscrollcommand=yscrollbar.set)\n",
    "\n",
    "            # create a frame to hold the checkboxes inside the canvas\n",
    "            checkbox_frame = tk.Frame(canvas)\n",
    "            checkbox_frame.columnconfigure(0, weight=1)\n",
    "            canvas.create_window((0, 0), window=checkbox_frame, anchor=tk.NW)\n",
    "\n",
    "            # create a checkbox for each result\n",
    "            checkboxes = []\n",
    "            for i, result in enumerate(self.result_list):\n",
    "                var = tk.BooleanVar(value=True)\n",
    "                checkbox = ttk.Checkbutton(checkbox_frame, text=f\"{result['Result Text']}\", variable=var)\n",
    "                checkbox.grid(row=i+2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "                checkboxes.append(var)\n",
    "\n",
    "            # update the canvas scroll region\n",
    "            checkbox_frame.update_idletasks()\n",
    "            canvas.config(scrollregion=canvas.bbox(tk.ALL))\n",
    "\n",
    "            # create a button to save selected results and close the window\n",
    "            def save_selected():\n",
    "                for i, checkbox in enumerate(checkboxes):\n",
    "                    if checkbox.get():\n",
    "                        selected_results.append(self.result_list[i])\n",
    "                with open(filename, 'w', encoding='utf-8') as file:\n",
    "                    if filename.endswith('.json'):\n",
    "                        file.write(json.dumps(selected_results, ensure_ascii=False, indent=4))\n",
    "                    elif filename.endswith('.csv'):\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(['Result Number', 'Result Text'])\n",
    "                        for result in selected_results:\n",
    "                            writer.writerow([result['Result Number'], result['Result Text']])\n",
    "                top.destroy()\n",
    "                # create a pandas dataframe from the selected results\n",
    "                df = pd.DataFrame(selected_results)\n",
    "\n",
    "                # perform any desired operations on the dataframe\n",
    "                # example: print the first 5 rows of the dataframe\n",
    "                print(df.head())\n",
    "\n",
    "            save_button = ttk.Button(checkbox_frame, text=\"Save Selected Results\", command=save_selected)\n",
    "            save_button.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "style = ttk.Style()\n",
    "style.theme_use('vista')\n",
    "scraper = ScraperGUI(root)\n",
    "root.mainloop()\n",
    "\n",
    "# USE THIS TO FIND PRICE IN MERCADOLIVRE.COM div.dynamic-carousel__item-container span.dynamic-carousel__price span\n",
    "# USE THIS TO FIND TITULO IN MERCADOLIVRE.COM div.dynamic-carousel__item-container h3.dynamic-carousel__title"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
