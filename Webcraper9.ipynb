{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Webscraping - First Coding with ChatGPT4 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://\")\n",
    "        self.select_label = ttk.Label(master, text=\"Select 1:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "        \n",
    "        self.select2_label = ttk.Label(master, text=\"Select 2:\")\n",
    "        self.select2_entry = ttk.Entry(master, width=80)\n",
    "        self.select3_label = ttk.Label(master, text=\"Select 3:\")\n",
    "        self.select3_entry = ttk.Entry(master, width=80)\n",
    "        self.select4_label = ttk.Label(master, text=\"Select 4:\")\n",
    "        self.select4_entry = ttk.Entry(master, width=80)\n",
    "        self.select5_label = ttk.Label(master, text=\"Select 5:\")\n",
    "        self.select5_entry = ttk.Entry(master, width=80)\n",
    "\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save)\n",
    "\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        \n",
    "        self.select2_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select2_entry.grid(row=2, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select3_label.grid(row=3, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select3_entry.grid(row=3, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select4_label.grid(row=4, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select4_entry.grid(row=4, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select5_label.grid(row=5, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select5_entry.grid(row=5, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        self.scrape_button.grid(row=6, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=7, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=6, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "\n",
    "        master.rowconfigure(7, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "\n",
    "    def scrape(self):\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        select1, select2, select3, select4, select5 = self.select_entry.get().split(\",\")\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        results1 = soup.select(select1.strip())\n",
    "        results2 = soup.select(select2.strip())\n",
    "        results3 = soup.select(select3.strip())\n",
    "        results4 = soup.select(select4.strip())\n",
    "        results5 = soup.select(select5.strip())\n",
    "\n",
    "        self.result_text.configure(state=\"normal\")\n",
    "        self.result_text.delete(\"1.0\", tk.END)\n",
    "        self.result_list = []\n",
    "\n",
    "        for i, (result1, result2, result3, result4, result5) in enumerate(\n",
    "            zip(results1, results2, results3, results4, results5)\n",
    "        ):\n",
    "            result_dict = {\n",
    "                \"Result Number\": i + 1,\n",
    "                \"Result1 Text\": result1.text.strip(),\n",
    "                \"Result2 Text\": result2.text.strip(),\n",
    "                \"Result3 Text\": result3.text.strip(),\n",
    "                \"Result4 Text\": result4.text.strip(),\n",
    "                \"Result5 Text\": result5.text.strip(),\n",
    "            }\n",
    "            self.result_list.append(result_dict)\n",
    "\n",
    "            self.result_text.insert(\n",
    "                tk.END,\n",
    "                f\"#{i + 1}\\n{select1}: {result1} -> {result1.text.strip()}\\n{select2}: {result2} -> {result2.text.strip()}\\n{select3}: {result3} -> {result3.text.strip()}\\n{select4}: {result4} -> {result4.text.strip()}\\n{select5}: {result5} -> {result5.text.strip()}\\n\\n\",\n",
    "            )\n",
    "\n",
    "        self.result_text.configure(state=\"disabled\")\n",
    "\n",
    "\n",
    "    def get_results(self, soup, select):\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            return soup.select(select)\n",
    "        else:\n",
    "            return soup.find_all(select)\n",
    "\n",
    "    ...\n",
    "\n",
    "    def save(self):\n",
    "        filetypes = [(\"JSON files\", \"*.json\"), (\"CSV files\", \"*.csv\")]\n",
    "        filename = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".json\", filetypes=filetypes\n",
    "        )\n",
    "\n",
    "        if filename:\n",
    "            selected_results = []\n",
    "\n",
    "            top = tk.Toplevel(self.master)\n",
    "            top.title(\"Select Results to Save\")\n",
    "            top.geometry(\"1280x720\")\n",
    "\n",
    "            canvas = tk.Canvas(top)\n",
    "            canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            yscrollbar = ttk.Scrollbar(\n",
    "                top, orient=tk.VERTICAL, command=canvas.yview\n",
    "            )\n",
    "            yscrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "            canvas.configure(yscrollcommand=yscrollbar.set)\n",
    "\n",
    "            checkbox_frame = tk.Frame(canvas)\n",
    "            checkbox_frame.columnconfigure(0, weight=1)\n",
    "            canvas.create_window((0, 0), window=checkbox_frame, anchor=tk.NW)\n",
    "\n",
    "            checkboxes = []\n",
    "            for i, result in enumerate(self.result_list):\n",
    "                var = tk.BooleanVar(value=True)\n",
    "                checkbox = ttk.Checkbutton(\n",
    "                    checkbox_frame,\n",
    "                    text=f\"{result['Result1 Text']} | {result['Result2 Text']} | {result['Result3 Text']} | {result['Result4 Text']} | {result['Result5 Text']}\",\n",
    "                    variable=var,\n",
    "                )\n",
    "                checkbox.grid(row=i + 2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "                checkboxes.append(var)\n",
    "\n",
    "            checkbox_frame.update_idletasks()\n",
    "            canvas.config(scrollregion=canvas.bbox(tk.ALL))\n",
    "\n",
    "            def save_selected():\n",
    "                for i, checkbox in enumerate(checkboxes):\n",
    "                    if checkbox.get():\n",
    "                        selected_results.append(self.result_list[i])\n",
    "                with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                    if filename.endswith(\".json\"):\n",
    "                        file.write(\n",
    "                            json.dumps(\n",
    "                                selected_results, ensure_ascii=False, indent=4\n",
    "                            )\n",
    "                        )\n",
    "                    elif filename.endswith(\".csv\"):\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(\n",
    "                            [\n",
    "                                \"Result Number\",\n",
    "                                \"Result1 Text\",\n",
    "                                \"Result2 Text\",\n",
    "                                \"Result3 Text\",\n",
    "                                \"Result4 Text\",\n",
    "                                \"Result5 Text\",\n",
    "                            ]\n",
    "                        )\n",
    "                        for result in selected_results:\n",
    "                            writer.writerow(\n",
    "                                [\n",
    "                                    result[\"Result Number\"],\n",
    "                                    result[\"Result1 Text\"],\n",
    "                                    result[\"Result2 Text\"],\n",
    "                                    result[\"Result3 Text\"],\n",
    "                                    result[\"Result4 Text\"],\n",
    "                                    result[\"Result5 Text\"],\n",
    "                                ]\n",
    "                            )\n",
    "                top.destroy()\n",
    "\n",
    "                df = pd.DataFrame(selected_results)\n",
    "                print(df.head())\n",
    "\n",
    "            save_button = ttk.Button(\n",
    "                checkbox_frame, text=\"Save Selected Results\", command=save_selected\n",
    "            )\n",
    "            save_button.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "style = ttk.Style()\n",
    "style.theme_use(\"vista\")\n",
    "scraper = ScraperGUI(root)\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://mercadolivre.com.br/\")\n",
    "        self.select_label = ttk.Label(master, text=\"Search:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "\n",
    "        # Add 5 input fields for saving columns\n",
    "        self.save_labels = [ttk.Label(master, text=f\"Column {i + 1}:\") for i in range(5)]\n",
    "        self.save_entries = [ttk.Entry(master, width=80) for _ in range(5)]\n",
    "\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.search_button = ttk.Button(master, text=\"Search\", command=self.search)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save)\n",
    "\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        # Place the save labels and entries in the grid\n",
    "        for i, (label, entry) in enumerate(zip(self.save_labels, self.save_entries)):\n",
    "            label.grid(row=i + 2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "            entry.grid(row=i + 2, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        self.search_button.grid(row=7, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.scrape_button.grid(row=7, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=8, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=7, column=1, padx=300, pady=5, sticky=\"w\")\n",
    "\n",
    "        master.rowconfigure(8, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "\n",
    "    def search(self):\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "\n",
    "        column_selectors = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            row = [result.text.strip()]\n",
    "            for selector in column_selectors:\n",
    "                column_result = result.select_one(selector)\n",
    "                if column_result:\n",
    "                    row.append(column_result.text.strip())\n",
    "                else:\n",
    "                    row.append('')\n",
    "\n",
    "            self.result_list.append(row)\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result.text.strip()}\\n\\n\")\n",
    "            count += 1\n",
    "        \n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        # Combine the column names and values from the save_entries\n",
    "        columns = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "        if not columns:\n",
    "            messagebox.showerror(\"Error\", \"No columns to save.\")\n",
    "            return\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Perform searches for each of the columns\n",
    "        column_results = []\n",
    "        for column in columns:\n",
    "            if column.startswith(\".\") or column.rfind(\".\") != -1 or column.rfind(\" \") != -1:\n",
    "                results = soup.select(column)\n",
    "            else:\n",
    "                results = soup.find_all(column)\n",
    "            \n",
    "            column_results.append([result.text.strip() for result in results])\n",
    "\n",
    "        # Save the results as a CSV file\n",
    "        filetypes = [('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(columns)\n",
    "\n",
    "                # Write the rows of data\n",
    "                max_rows = max([len(column_data) for column_data in column_results])\n",
    "                for row_idx in range(max_rows):\n",
    "                    row = [column_data[row_idx] if row_idx < len(column_data) else '' for column_data in column_results]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            # Create a pandas dataframe from the saved results\n",
    "            df = pd.read_csv(filename)\n",
    "\n",
    "            # Perform any desired operations on the dataframe\n",
    "            # Example: print the first 5 rows of the dataframe\n",
    "            print(df.head())\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        # Combine the column names and values from the save_entries\n",
    "        columns = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "        if not columns:\n",
    "            messagebox.showerror(\"Error\", \"No columns to save.\")\n",
    "            return\n",
    "\n",
    "        # Save the results as a CSV file\n",
    "        filetypes = [('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(columns)\n",
    "                for result in self.result_list:\n",
    "                    row = [result['Result Text'] if column in result['Result Text'] else '' for column in columns]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            # Create a pandas dataframe from the saved results\n",
    "            df = pd.read_csv(filename)\n",
    "\n",
    "            # Perform any desired operations on the dataframe\n",
    "            # Example: print the first 5 rows of the dataframe\n",
    "            print(df.head())\n",
    "\n",
    "root = tk.Tk()\n",
    "style = ttk.Style()\n",
    "style.theme_use('vista')\n",
    "scraper = ScraperGUI(root)\n",
    "root.mainloop()\n",
    "\n",
    "# USE THIS TO FIND PRICE IN MERCADOLIVRE.COM div.dynamic-carousel__item-container span.dynamic-carousel__price span\n",
    "# USE THIS TO FIND TITULO IN MERCADOLIVRE.COM div.dynamic-carousel__item-container h3.dynamic-carousel__title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ttttt.csv')\n",
    "df.head(40)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>WORKING VERSION</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  div.dynamic-carousel__item-container h3.dynamic-carousel__title  \\\n",
      "0  Kit 10 Cuecas Box Boxer Estampadas Masculino A...                \n",
      "1  Smart TV Philco PTV50G10AG11SK DLED Android TV...                \n",
      "2  Tapete 2,00x1,50 Tay Day Shaggy Mega Promoção ...                \n",
      "3  Smartphone Motorola Moto G22 Dual 6,5 128gb 4g...                \n",
      "4  Maquininha Point Smart - A Máquina De Cartão D...                \n",
      "\n",
      "  div.dynamic-carousel__item-container span.dynamic-carousel__price span  \n",
      "0                                              R$ 43                      \n",
      "1                                           R$ 2.177                      \n",
      "2                                              R$ 86                      \n",
      "3                                           R$ 1.039                      \n",
      "4                                             R$ 217                      \n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://mercadolivre.com.br/\")\n",
    "        self.select_label = ttk.Label(master, text=\"Search:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "\n",
    "        # Add 5 input fields for saving columns\n",
    "        self.save_entries = [ttk.Entry(master, width=80) for _ in range(5)]\n",
    "\n",
    "        # Add 5 input fields for custom column names\n",
    "        self.column_name_entries = [ttk.Entry(master, width=20) for _ in range(5)]\n",
    "\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.search_button = ttk.Button(master, text=\"Search\", command=self.search)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save)\n",
    "\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        # Place the save entries in the grid\n",
    "        for i, entry in enumerate(self.save_entries):\n",
    "            entry.grid(row=i + 2, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "\n",
    "        # Place the column name entries in the grid\n",
    "        for i, entry in enumerate(self.column_name_entries):\n",
    "            entry.grid(row=i + 2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "        self.search_button.grid(row=7, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.scrape_button.grid(row=7, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=8, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=7, column=1, padx=300, pady=5, sticky=\"w\")\n",
    "\n",
    "        master.rowconfigure(8, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def search(self):\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "\n",
    "        column_selectors = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            row = [result.text.strip()]\n",
    "            for selector in column_selectors:\n",
    "                column_result = result.select_one(selector)\n",
    "                if column_result:\n",
    "                    row.append(column_result.text.strip())\n",
    "                else:\n",
    "                    row.append('')\n",
    "\n",
    "            self.result_list.append(row)\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result.text.strip()}\\n\\n\")\n",
    "            count += 1\n",
    "        \n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        # Combine the column names and values from the save_entries\n",
    "        columns = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "        if not columns:\n",
    "            messagebox.showerror(\"Error\", \"No columns to save.\")\n",
    "            return\n",
    "\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\",\n",
    "            \"Content-Type\": \"text/html\",\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Perform searches for each of the columns\n",
    "        column_results = []\n",
    "        for column in columns:\n",
    "            if column.startswith(\".\") or column.rfind(\".\") != -1 or column.rfind(\" \") != -1:\n",
    "                results = soup.select(column)\n",
    "            else:\n",
    "                results = soup.find_all(column)\n",
    "            \n",
    "            column_results.append([result.text.strip() for result in results])\n",
    "\n",
    "        # Save the results as a CSV file\n",
    "        filetypes = [('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(columns)\n",
    "\n",
    "                # Write the rows of data\n",
    "                max_rows = max([len(column_data) for column_data in column_results])\n",
    "                for row_idx in range(max_rows):\n",
    "                    row = [column_data[row_idx] if row_idx < len(column_data) else '' for column_data in column_results]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            # Create a pandas dataframe from the saved results\n",
    "            df = pd.read_csv(filename)\n",
    "\n",
    "            # Perform any desired operations on the dataframe\n",
    "            # Example: print the first 5 rows of the dataframe\n",
    "            print(df.head())\n",
    "\n",
    "\n",
    "    def save(self):\n",
    "        # Combine the column names and values from the save_entries\n",
    "        columns = [entry.get() for entry in self.save_entries if entry.get()]\n",
    "        if not columns:\n",
    "            messagebox.showerror(\"Error\", \"No columns to save.\")\n",
    "            return\n",
    "\n",
    "        # Save the results as a CSV file\n",
    "        filetypes = [('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                \n",
    "                # Replace default column names with custom names if provided\n",
    "                custom_columns = [entry.get() for entry in self.column_name_entries]\n",
    "                final_columns = [custom if custom else default for custom, default in zip(custom_columns, columns)]\n",
    "                writer.writerow(final_columns)\n",
    "\n",
    "                for result in self.result_list:\n",
    "                    row = [cell for cell in result]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            # Create a pandas dataframe from the saved results\n",
    "            df = pd.read_csv(filename)\n",
    "\n",
    "            # Perform any desired operations on the dataframe\n",
    "            # Example: print the first 5\n",
    "\n",
    "                # Perform any desired operations on the dataframe\n",
    "                # Example: print the first 5 rows of the dataframe\n",
    "            print(df.head())\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "style = ttk.Style()\n",
    "style.theme_use('vista')\n",
    "scraper = ScraperGUI(root)\n",
    "root.mainloop()\n",
    "\n",
    "# USE THIS TO FIND PRICE IN MERCADOLIVRE.COM div.dynamic-carousel__item-container span.dynamic-carousel__price span\n",
    "# USE THIS TO FIND TITULO IN MERCADOLIVRE.COM div.dynamic-carousel__item-container h3.dynamic-carousel__title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
