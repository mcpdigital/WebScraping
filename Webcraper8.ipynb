{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# USE THIS TO FIND PRICE IN MERCADOLIVRE.COM div.dynamic-carousel__item-container span.dynamic-carousel__price span\n",
    "# USE THIS TO FIND TITULO IN MERCADOLIVRE.COM div.dynamic-carousel__item-container h3.dynamic-carousel__title\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://\")\n",
    "        self.select_label = ttk.Label(master, text=\"Select:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        #self.result_text = tk.Text(master)\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save)\n",
    "        self.save = self.save\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        # self.url_label.grid(row=0, column=0, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.scrape_button.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=3, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=2, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "                # Configure rows and columns to resize automatically\n",
    "        master.rowconfigure(3, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "       # master.rowconfigure(4, weight=1)\n",
    "        #self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', 'Content-Type': 'text/html'}\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # if(select.rfind(\".\") == -1):\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "        \n",
    "        \n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            \n",
    "            result_dict = {'Result Number': count, 'Result Text': str(result.text.strip())}\n",
    "            self.result_list.append(result_dict)  # add result to list\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result.text.strip()}\\n\\n\")\n",
    "            count += 1\n",
    "        \n",
    "        self.result_text.configure(state='disabled')\n",
    "        \n",
    "    def save(self):\n",
    "        # use file dialog to get the filename and file type to save\n",
    "        filetypes = [('JSON files', '*.json'), ('CSV files', '*.csv')]\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".json\", filetypes=filetypes)\n",
    "\n",
    "        if filename:\n",
    "            selected_results = []  # list to save selected results\n",
    "\n",
    "            # create a Toplevel window to display checkboxes for each result\n",
    "            top = tk.Toplevel(self.master)\n",
    "            top.title(\"Select Results to Save\")\n",
    "            top.geometry(\"1280x720\")\n",
    "\n",
    "            # create a canvas to hold the checkboxes\n",
    "            canvas = tk.Canvas(top)\n",
    "            canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)\n",
    "\n",
    "            # add a scrollbar to the canvas\n",
    "            yscrollbar = ttk.Scrollbar(top, orient=tk.VERTICAL, command=canvas.yview)\n",
    "            yscrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "            canvas.configure(yscrollcommand=yscrollbar.set)\n",
    "\n",
    "            # create a frame to hold the checkboxes inside the canvas\n",
    "            checkbox_frame = tk.Frame(canvas)\n",
    "            checkbox_frame.columnconfigure(0, weight=1)\n",
    "            canvas.create_window((0, 0), window=checkbox_frame, anchor=tk.NW)\n",
    "\n",
    "            # create a checkbox for each result\n",
    "            checkboxes = []\n",
    "            for i, result in enumerate(self.result_list):\n",
    "                var = tk.BooleanVar(value=True)\n",
    "                checkbox = ttk.Checkbutton(checkbox_frame, text=f\"{result['Result Text']}\", variable=var)\n",
    "                checkbox.grid(row=i+2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "                checkboxes.append(var)\n",
    "\n",
    "            # update the canvas scroll region\n",
    "            checkbox_frame.update_idletasks()\n",
    "            canvas.config(scrollregion=canvas.bbox(tk.ALL))\n",
    "\n",
    "            # create a button to save selected results and close the window\n",
    "            def save_selected():\n",
    "                for i, checkbox in enumerate(checkboxes):\n",
    "                    if checkbox.get():\n",
    "                        selected_results.append(self.result_list[i])\n",
    "                with open(filename, 'w', encoding='utf-8') as file:\n",
    "                    if filename.endswith('.json'):\n",
    "                        file.write(json.dumps(selected_results, ensure_ascii=False, indent=4))\n",
    "                    elif filename.endswith('.csv'):\n",
    "                        writer = csv.writer(file)\n",
    "                        writer.writerow(['Result Number', 'Result Text'])\n",
    "                        for result in selected_results:\n",
    "                            writer.writerow([result['Result Number'], result['Result Text']])\n",
    "                top.destroy()\n",
    "                # create a pandas dataframe from the selected results\n",
    "                df = pd.DataFrame(selected_results)\n",
    "\n",
    "                # perform any desired operations on the dataframe\n",
    "                # example: print the first 5 rows of the dataframe\n",
    "                print(df.head())\n",
    "\n",
    "            save_button = ttk.Button(checkbox_frame, text=\"Save Selected Results\", command=save_selected)\n",
    "            save_button.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "# create a style object\n",
    "style = ttk.Style()\n",
    "\n",
    "# set the theme\n",
    "style.theme_use('vista')\n",
    "scraper = ScraperGUI(root)\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://\")\n",
    "        self.select_label = ttk.Label(master, text=\"Select:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save_results)\n",
    "        self.marked_results = {}  # initialize dictionary to store marked results\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.scrape_button.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=3, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=2, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        # Configure rows and columns to resize automatically\n",
    "        master.rowconfigure(3, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', 'Content-Type': 'text/html'}\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            result_text = str(result.text.strip())\n",
    "            result_dict = {'Result Number': count, 'Result Text': result_text}\n",
    "            self.result_list.append(result_dict)  # add result to list\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result_text}\\n\\n\")\n",
    "            count += 1\n",
    "\n",
    "            # add checkbutton to mark result\n",
    "            var = tk.BooleanVar(value=False)\n",
    "            cb = ttk.Checkbutton(self.result_text, variable=var, onvalue=True, offvalue=False, command=lambda: self.mark_result(count, var.get()))\n",
    "            cb.grid(row=count+3, column=0, sticky='w')\n",
    "            self.marked_results[count] = False # initialize marked result as False\n",
    "            self.result_text.window_create(tk.END, window=cb)\n",
    "            self.result_text.insert(tk.END, '\\n')\n",
    "            self.result_text.configure(state='disabled')\n",
    "\n",
    "    def mark_result(self, result_number, value):\n",
    "        self.marked_results[result_number] = value\n",
    "\n",
    "    def save_results(self):\n",
    "        marked_results = [result for result in self.result_list if self.marked_results[result['Result Number']] == True]\n",
    "        with open('results.json', 'w') as f:\n",
    "            json.dump(marked_results, f, indent=4)\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_text.insert(tk.END, f\"{len(marked_results)} marked results saved to 'results.json'\")\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "root = tk.Tk()\n",
    "ScraperGUI(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://\")\n",
    "        self.select_label = ttk.Label(master, text=\"Select:\")\n",
    "        self.select_entry = ttk.Entry(master, width=80)\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save_results)\n",
    "        self.marked_results = []  # initialize list to store marked results\n",
    "        self.last_five_results = [] #initialize list to store last five results\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.select_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.select_entry.grid(row=1, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.scrape_button.grid(row=2, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=3, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=2, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        # Configure rows and columns to resize automatically\n",
    "        master.rowconfigure(3, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def scrape(self):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36', 'Content-Type': 'text/html'}\n",
    "        url = self.url_entry.get()\n",
    "        select = self.select_entry.get()\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        if select.startswith(\".\") or select.rfind(\".\") != -1 or select.rfind(\" \") != -1:\n",
    "            results = soup.select(select)\n",
    "        else:\n",
    "            results = soup.find_all(select)\n",
    "\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        count = 1\n",
    "        for result in results:\n",
    "            if len(self.last_five_results) < 5:\n",
    "                self.last_five_results.append(result)\n",
    "            result_text = str(result.text.strip())\n",
    "            result_dict = {'Result Number': count, 'Result Text': result_text}\n",
    "            self.result_list.append(result_dict)  # add result to list\n",
    "            self.result_text.insert(tk.END, f\"{select}  #{count}: {result} -> {result_text}\\n\\n\")\n",
    "            count += 1\n",
    "\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "    def save_results(self):\n",
    "        for i, result in enumerate(self.last_five_results):\n",
    "            # create button with text\n",
    "            btn = tk.Button(self.result_text, text=f\"Result {i+1}\", command=lambda idx=i: self.mark_result(idx))\n",
    "            # insert button into text widget\n",
    "            self.result_text.window_create(tk.END, window=btn)\n",
    "            # insert newline character\n",
    "            self.result_text.insert(tk.END, \"\\n\")\n",
    "\n",
    "    def mark_result(self, idx):\n",
    "        result = self.last_five_results[idx]\n",
    "        self.marked_results.append(result)  # add marked result to list\n",
    "        self.last_five_results.pop(idx)  # remove result from last five results list\n",
    "\n",
    "root = tk.Tk()\n",
    "app = ScraperGUI(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"EDA Web Scraper (Jupyter) - Marcelo C. Plaza\")\n",
    "        master.geometry(\"1280x720\")\n",
    "\n",
    "        self.url_label = ttk.Label(master, text=\"URL:\")\n",
    "        self.url_entry = ttk.Entry(master, width=80)\n",
    "        self.url_entry.insert(0, \"https://\")\n",
    "        self.select_labels = []\n",
    "        self.select_entries = []\n",
    "        for i in range(5):\n",
    "            label = ttk.Label(master, text=f\"Search String {i+1}:\")\n",
    "            entry = ttk.Entry(master, width=80)\n",
    "            self.select_labels.append(label)\n",
    "            self.select_entries.append(entry)\n",
    "            label.grid(row=2+i, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "            entry.grid(row=2+i, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.scrape_button = ttk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.result_text = tk.Text(master, wrap=\"word\")\n",
    "        self.save_button = ttk.Button(master, text=\"Save\", command=self.save_results)\n",
    "        self.result_list = []  # initialize list to store all results\n",
    "        self.url_label.grid(row=0, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "        self.url_entry.grid(row=0, column=1, padx=5, pady=5, sticky=\"we\")\n",
    "        self.scrape_button.grid(row=8, column=1, padx=5, pady=5, sticky=\"w\")\n",
    "        self.result_text.grid(row=9, column=0, columnspan=2, padx=5, pady=5, sticky=\"nsew\")\n",
    "        self.save_button.grid(row=8, column=1, padx=100, pady=5, sticky=\"w\")\n",
    "        # Configure rows and columns to resize automatically\n",
    "        master.rowconfigure(9, weight=1)\n",
    "        master.columnconfigure(1, weight=1)\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "\n",
    "    def scrape(self):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
    "            'Content-Type': 'text/html'\n",
    "        }\n",
    "        url = self.url_entry.get()\n",
    "        self.result_list = []  # save all results in a class attribute\n",
    "        max_results = 0\n",
    "        for i, select in enumerate(self.select_entries):\n",
    "            if select.get():\n",
    "                response = requests.get(url, headers=headers)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                if select.get().startswith(\".\") or select.get().rfind(\".\") != -1 or select.get().rfind(\" \") != -1:\n",
    "                    results = soup.select(select.get())\n",
    "                else:\n",
    "                    results = soup.find_all(select.get())\n",
    "                count = 1\n",
    "                for result in results:\n",
    "                    result_text = str(result.text.strip())\n",
    "                    result_dict = {\n",
    "                        f'String{i+1}_Result{count}': result_text,\n",
    "                        'Search String': f\"Search String {i+1}\",\n",
    "                    }\n",
    "                    self.result_list.append(result_dict)  # add result to list\n",
    "                    count += 1\n",
    "                max_results = max(max_results, count - 1)\n",
    "\n",
    "        # create a dictionary to convert the list of result dictionaries into a dataframe\n",
    "        dict_data = {}\n",
    "        for i in range(1, 6):\n",
    "            col_name = f\"Search String {i}\"\n",
    "            result_col = [result_dict.get(f\"String{i}_Result{j}\", \"\") for result_dict in self.result_list for j in range(1, max_results+1)]\n",
    "\n",
    "            dict_data[col_name] = result_col\n",
    "\n",
    "        # create a pandas dataframe from the result dictionary\n",
    "        df = pd.DataFrame(dict_data)\n",
    "\n",
    "        # display the dataframe in the GUI\n",
    "        self.result_text.configure(state='normal')\n",
    "        self.result_text.delete('1.0', tk.END)\n",
    "        self.result_text.insert('1.0', df.to_string())\n",
    "        self.result_text.configure(state='disabled')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def save_results(self):\n",
    "        if not self.result_list:\n",
    "            tk.messagebox.showwarning(\"No Results\", \"There are no results to save.\")\n",
    "            return\n",
    "        file_types = [('Comma Separated Values', '*.csv'), ('JSON', '*.json')]\n",
    "        file_name = tk.filedialog.asksaveasfilename(defaultextension='.csv', filetypes=file_types)\n",
    "        if file_name:\n",
    "            df = pd.DataFrame(self.result_list)\n",
    "            if file_name.endswith('.json'):\n",
    "                df.to_json(file_name, orient='records')\n",
    "            else:\n",
    "                df.to_csv(file_name, index=False)\n",
    "\n",
    "root = tk.Tk()\n",
    "app = ScraperGUI(root)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
