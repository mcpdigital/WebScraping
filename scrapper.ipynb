{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, url, tags):\n",
    "        self.url = url\n",
    "        self.tags = tags\n",
    "        \n",
    "    def scrape(self):\n",
    "        response = requests.get(self.url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        results = []\n",
    "        for tag in self.tags:\n",
    "            elements = soup.find_all(tag)\n",
    "            for element in elements:\n",
    "                results.append(element.text)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Example Domain', 'This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.', 'More information...']\n"
     ]
    }
   ],
   "source": [
    "scraper = Scraper('https://example.com', ['h1', 'p'])\n",
    "results = scraper.scrape()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Web Scraper\")\n",
    "\n",
    "        # URL input\n",
    "        self.url_label = tk.Label(master, text=\"Enter URL:\")\n",
    "        self.url_label.pack()\n",
    "        self.url_entry = tk.Entry(master)\n",
    "        self.url_entry.pack()\n",
    "\n",
    "        # HTML tags input\n",
    "        self.tags_label = tk.Label(master, text=\"Enter HTML tags (separated by commas):\")\n",
    "        self.tags_label.pack()\n",
    "        self.tags_entry = tk.Entry(master)\n",
    "        self.tags_entry.pack()\n",
    "\n",
    "        # Scrape button\n",
    "        self.scrape_button = tk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.scrape_button.pack()\n",
    "\n",
    "        # Results text box\n",
    "        self.results_text = tk.Text(master)\n",
    "        self.results_text.pack()\n",
    "\n",
    "    def scrape(self):\n",
    "        url = self.url_entry.get()\n",
    "        tags = [tag.strip() for tag in self.tags_entry.get().split(\",\")]\n",
    "        scraper = Scraper(url, tags)\n",
    "        results = scraper.scrape()\n",
    "        self.results_text.delete(\"1.0\", tk.END)\n",
    "        for result in results:\n",
    "            self.results_text.insert(tk.END, result + \"\\n\")\n",
    "\n",
    "root = tk.Tk()\n",
    "scraper_gui = ScraperGUI(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Scraper:\n",
    "    def __init__(self, url, tags):\n",
    "        self.url = url\n",
    "        self.tags = tags\n",
    "        \n",
    "    def scrape(self):\n",
    "        response = requests.get(self.url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        results = []\n",
    "        for tag in self.tags:\n",
    "            elements = soup.find_all(tag)\n",
    "            for element in elements:\n",
    "                results.append(element.text)\n",
    "        return results\n",
    "\n",
    "class ScraperGUI:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Web Scraper\")\n",
    "\n",
    "        # URL input\n",
    "        self.url_label = tk.Label(master, text=\"Enter URL:\")\n",
    "        self.url_label.pack()\n",
    "        self.url_entry = tk.Entry(master)\n",
    "        self.url_entry.pack()\n",
    "\n",
    "        # HTML tags input\n",
    "        self.tags_label = tk.Label(master, text=\"Enter HTML tags (separated by commas):\")\n",
    "        self.tags_label.pack()\n",
    "        self.tags_entry = tk.Entry(master)\n",
    "        self.tags_entry.pack()\n",
    "\n",
    "        # Scrape button\n",
    "        self.scrape_button = tk.Button(master, text=\"Scrape\", command=self.scrape)\n",
    "        self.scrape_button.pack()\n",
    "\n",
    "        # Results text box\n",
    "        self.results_text = tk.Text(master)\n",
    "        self.results_text.pack()\n",
    "\n",
    "    def scrape(self):\n",
    "        url = self.url_entry.get()\n",
    "        tags = [tag.strip() for tag in self.tags_entry.get().split(\",\")]\n",
    "        scraper = Scraper(url, tags)\n",
    "        results = scraper.scrape()\n",
    "        self.results_text.delete(\"1.0\", tk.END)\n",
    "        for result in results:\n",
    "            self.results_text.insert(tk.END, result + \"\\n\")\n",
    "\n",
    "root = tk.Tk()\n",
    "scraper_gui = ScraperGUI(root)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
